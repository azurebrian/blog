{
  
    
        "post0": {
            "title": "Stored Access Policies For Azure Files",
            "content": "Lately, at work, I’ve been helping to lead an implementation of an Azure Files share for a client. This is the second client we’ve set up with one, and it’s a pretty elegant solution that mitigates the need for an on-prem file server. It’s also available everywhere and doesn’t require being connected to a VPN, just to name a couple more benefits. In order to provision access, we usually setup end users with either a mapped drive or, more recently, with Azure Storage Explorer. There are numerous advantages to using Storage Explorer, in my opinion, but that’s not really the scope of this post. However, the ability to use an SAS (Shared Access Signature) URI is one that is relevant. . There are numerous ways to secure access to an Azure Files share. You can provision an Azure AD account and use traditional RBAC roles at the storage account level. That way when a user logs in from Storage Explorer, the portal, or the portal app, the user gets the desired access. If you’re using a Classic storage account, this might result in granting too much access to an end user, though. You’re reduced to using roles such as “Contributor” and at the entire storage account level. If your storage account is of the Resource Manager variety you can use new RBAC roles to get more fine-grained control. If configuring a mapped drive, you can use one of the two storage account keys to setup access. It’s a bit nuclear because it’s really intended to be used as administrative access, but the only way to map a drive is to use a storage account key per this article, in fact. You can’t use an SAS URI as you can with Storage Explorer. As I eluded to earlier, this is just one of the big feathers in the cap for using Storage Explorer over mapped drives. You can also create an account SAS (because it’s defined at the storage account level), or a Service SAS (defined at the Blob, File, Table, or Queue level) as mentioned in this SAS overview. Whew…I’m already going cross-eyed :dizzy_face:. But what happens if you have a requirement for controlling access for a contractor or a temporary employee? What’s the best way to handle that? And what if your share resides in a Classic deployment model and you can’t take advantage of the more fine-grained RBAC roles? We’re going to talk about a bit of a hybrid approach using the aforementioned Service SAS. . A plain ol’ SAS without any sort of policy is known as an ad-hoc SAS, as defined in this article. It’s dubbed “ad-hoc” because all of the attributes that define the SAS are stored right in the URI. During my research on the best way to balance access to the share with proper security, I found that the ad-hoc Service SAS (Service because I only wanted to provision access to the Files service) is a decent solution. It’s great for quick hits and temporary access where the access will expire quickly. When using these, the rule of thumb is to not set the expiration date for too long into the future. If a user’s contract isn’t renewed for example, you want the SAS to expire pretty quickly so the risk of unauthorized access is at a minimum. That’s great, but what if you don’t know when a user’s contract will be up, or how many times they’ll be renewed, etc. Also, maybe you don’t want to have to deal with constantly renewing their access every renewal period. Maybe still you’d rather be able to revoke a user’s access on-demand rather than wait for a SAS to expire, leaving the share exposed in the meantime. In the ad-hoc SAS scenario and even the mapped drive scenario, a storage account key is used to sign an SAS or setup administrative access with a mapped drive. This is a problem because if we ever need to expire access or the SAS or storage account key get compromised in any way, you have to regenerate or rotate the storage account keys. This could have major implications on business contnuity. Applications relying on those keys would have to get updated, users using SAS URIs or mapped drives signed with that key would have to be configured with new ones and all of it would have to be remedied basically at the same time. So we need some kind of choke point that decouples us from direct access to the storage account keys. Enter the Stored Access Policy. . In my research, I came across Hussein Salman’s excellent blog post series on SAS and specifically on using them in conjunction with stored access policies. It really helped me weed thru the confusing landscape of secure, temporary access as I eluded to earlier. Hussein’s post on policies showed how to configure such a policy for Blob containers via the Azure portal. Yet, to my surprise when I went to the Azure Files section of the portal, there was no such UI for configuring a policy. So, I endeavored to find out how to do it. I eventually figured out how to do it using the Azure CLI and from Storage Explorer as well. The latter I didn’t even realize until I was writing this blog post. It only takes a few commands or steps and at the end you’ll have an Azure Files Service URI based on a stored access policy which you can hand your end user that’s as locked down as you like. You’ll also be able to revoke that URI at any time, like when your client informs you they haven’t renewed the end user’s contract. And perhaps best of all, you’ll insulate yourself from having to regenerate storage account keys in an unplanned fashion. Let’s look at the CLI approach first: . Azure CLI . These commands can be found in the Azure CLI documentation and basically follow the CRUD commands you’d expect. Of course, you need to use az login and login with an account that has sufficient permissions to run these commands. The first command we want to run creates the Shared Access Policy: . az storage share policy create --name OneDayAccessFileShare --share-name &lt;some share name&gt; --expiry 2020-05-10T18:08:01Z --permissions rwdl --account-name &lt;some storage account name&gt; . We’re creating a Stored Access Policy that’s scoped to a file share. We give it a good, descriptive name: OneDayAccessFileShare which implies this will be just for a day as we’re testing. We then specify the share name which has to match the actual share name of course. The expiration value, which for our testing purposes is about a day in the future. This can be set to any point in the future, such as some number of months or years down the road. As mentioned already, you want to try and keep these durations as short as possible, but we will see how to revoke these should we need to expire them manually. We then specify the permissions needed. In our test case here we’re granting all of them: read, write, delete, list. Finally, we specify the storage account name. . az storage share policy list --account-name &lt;some storage account name&gt; --share-name &lt;some share name&gt; . As you can probably guess, this command just lists out the policy to ensure it took, and you get something that looks like this: . &quot;OneDayAccessFileShare&quot;: { &quot;expiry&quot;: &quot;2020-05-10T18:08:01+00:00&quot;, &quot;permission&quot;: &quot;rwdl&quot;, &quot;start&quot;: null }, . Now that we’ve got our policy created, we can generate an SAS: . az storage share generate-sas --name &lt;some share name&gt; --policy-name OneDayAccessFileShare --account-name &lt;some storage account name&gt; . This generates output that looks something like this: . sv=2018-11-09&amp;si=OneDayAccessFileShare&amp;sr=s&amp;sig=Lpj%2Bqz50nM8J7z4AgMXWzHOe6tzDELjg1sIO5q3/fj0%3D . This is basically a query string that we can append to our file share URL. If you don’t know your file share URL, the easiest way to find it, in my opinion, is to look at the properties for the file share in the portal. Notice the reference to the policy we created assigned to the si variable. . You would now take the full URI and send it to the end user for access in Storage Explorer. You definitely want to take care in doing this, because anyone with this SAS URI will be granted access. . But what about revoking the signature as we mentioned earlier? There’s one more command we need to use in order to revoke the SAS if we need to expire it on-demand for any reason: . az storage share policy update --name OneDayAccessFileShare --share-name &lt;some share name --expiry 2020-05-08T18:08:01Z --permissions rwdl --account-name &lt;some share name&gt; . To expire the SAS we update the policy to use an expiration date in the past. This automatically revokes the SAS by way of the policy. Because the SAS gets sent with each request to the share, this will pretty much immediately revoke access to anyone using this SAS URI. You can also just delete the policy, but the good thing about just updating the expiration date is that updating it back to a future date enables the SAS again. So now you have full control over a user’s access with just one line in the Azure CLI! . Azure Storage Explorer . As I mentioned, while I was writing this post I was pleasantly surprised to find that the UI I had been looking for in the portal is actually baked into Storage Explorer. That’s ok, it made me get familiar with the relevant Azure CLI commands and it’s nice to know more than one way to skin a cat. Basically, we’re going to do the same thing we did with the commands above, just in Storage Explorer. And lest I not mention it, kudos to Microsoft for making Storage Explorer, and the CLI for that matter, cross-platform! This is yet another benefit of Storage Explorer in that it’s the same access, interface and functionality on any OS. I’m doing all of this on my MacBook Pro and it’s the same experience as on Windows. And for those of us supporting different end user preferences and environments, consistency is a great thing. :+1: . Just as with the CLI, you need to be logged in to Storage Explorer with an account that has the appopriate privileges to perform these operations. Let’s start with creating the policy. Right-click on your file share and you’ll see options similar to these: . . Choose Manage Access Policies and you’ll see a screen similar to this: . . If you’ve already perfomed the CLI steps above, you’ll see one or more policies listed. You’ll notice you basically have the same options available to you as with the CLI steps. One notable exception is the presence of a Create permission. Per the CLI documentation for az storage share policy create the only permissions you can specify via the CLI are rwdl. There is no c or mention of a create permission. Yet, in the portal when creating an ad-hoc Files Service SAS you can specify one and in Storage Explorer you can as well. I don’t see any difference in behavior in Storage Explorer using either method however, as you can still upload files to the share, create folders and manipulate them as you would like. It is curious to me that there’s a discrepancy, but I honestly don’t know why this is. If you know, please comment and share your wisdom! . Once the policy is created, you can right-click again on the share and choose Get Shared Access Signature: . . You’ll see a screen like this: . . At the very top, you can specify the policy you just created and the relevant values will populate based on how you set your policy, other than the Start time: field. It will basically be null. Clicking create will create a URI that you can share with your end user. You don’t even have to append the SAS with the endpoint! Although, it gives you a query string representation as well :grin:. . Summary . Using Stored Access Policies to control access to resources like Azure Files shares has three distinct advantages: . We create a choke-point where you can control access, particularly to users outside of an organization. | We eliminate the need to rotate/regenerate storage account keys which could impact availability should you need to revoke access. | We allow for fine-grained control of permissions to Azure Files shares no matter which deployment model we’re using. | I’d love to hear how you’re securing your Azure Files shares or any constructive feedback you might have. Hopefully this post will help a little the next time you or I are weeding through all the possible options Azure has to offer. .",
            "url": "https://azurebrian.github.io/blog/how-to/2020/05/11/Stored-Access-Policies-For-Azure-Files.html",
            "relUrl": "/how-to/2020/05/11/Stored-Access-Policies-For-Azure-Files.html",
            "date": " • May 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Azure Fundamentals Certification Preparation",
            "content": "UPDATE: Today, 09-24-2020, I took and passed the AZ-900 exam. I wanted to revisit this post with my thoughts and impressions now that I can look back on the process. Of course, I can’t dive into specifics regarding the exam or the questions, but suffice it to say that I thought it was very fair. I have to say that the MeasureUp Practice tests prepared me very well. In fact, I think they were harder than the actual exam. So, I highly recommend using them. I also was struck by how much I fell back on what I had experienced by actually using Azure to deploy resources or just play around. So, I would definitely also say that any time you can spend in Azure deploying VMs, configuring resources, or just doing Microsoft Learn modules that allow you to use a sandbox, is well worth it. Furthermore, if you get Azure credits via a Visual Studio subscription through your company or otherwise, take advantage of them. It’s $150 in free money every month to play around and tinker! I also really appreciated being able to use Tim Warner’s study guide on specific topics I felt I needed reinforcement on. And Mike Pfeiffer’s Cloudskills.io podcasts are really good as well. In fact, these fellas have a one-day bootcamp coming up in October. So, if you’re thinking about starting your cloud journey by taking this exam, it’s a great time to do it. Good luck and please leave a comment below if you have any other helpful tips or resources! . Greetings! I wanted to do a blog post about studying for the Azure Fundamentals (AZ-900) exam. I’ve technically been using Azure in my consulting position for a little over two years now. However, I’ve really started leaning into it, and getting serious about learning it, within the last year. My goal is to blend my IT administration background with my development career and pursuing Azure, and the solutions it provides, well that really seems like the ideal amalgamation of the two to me. I’m passionate about doing IT right, and I’m also passionate about clean development practices. So, I feel this is a pretty exciting time to be learning Azure. I’ve been fortunate to get my hands dirty with real-world projects during this time. However, like many of you I’m sure, I do want to formalize that experience by obtaining Azure-based certifications. Whether it’s angling for more money or just wanting others to take you seriously, there’s no doubt these certications have the potential to unlock doors and change mindsets. . Given all of that, it seemed only natural to start at the ground floor, so to speak. The Azure Fundamentals exam is aimed at a much broader audience than just us techies. However, I feel it may be deceptively hard. No, I don’t think I’ll have to configure a hybrid network connection or some crazy storage solution, but I also can’t remember another exam that had the potential to cover such a breadth of material. We all know that Azure is a beast and constanly changing with new offerings and updates to existing ones. So, it’s a little unnerving when I look at the range of material. I do think it helps to have real-world projects to practice recommending services and pricing estimates, though. So, I hope that’s building up repetition and the muscle memory I need to retain the knowledge. . The other objective I had for this blog post was to let it serve as a way to curate a list of training resources. I think it might be useful to break it down in terms of curriculum offerings, study guides, practice tests, and podcasts. I soak up a lot of knowledge from podcasts so I want to make sure I include those too. So, here’s what I’ve got so far: . Curriculum . Azure fundamentals Learning Path - This has been my primary curriculum for studying. It’s 12 modules. It’s been great because it allows for some hands-on practice in a free Azure lab environment to cement some concepts. What’s more is it’s free and virtual, which is awesome because my company doesn’t typically pay for training classes. And, it can be done remote, of course, in these crazy times. It really didn’t take that long to get through and it’s gamified so you get the thrill of leveling up! | Jim Cheshire’s Exam Ref AZ-900 Microsoft Azure Fundamentals 1st Edition - I have a sample of this on my Kindle app, but I confess, I haven’t really looked at it much yet. | . Study Guides . Tim Warner’s Exam AZ-900 MS Azure Fundamentals Study Guide YouTube Playlist - The awesome Tim Warner has a video series that, when finished, will consist of no less than 63 study guide videos. Free! | Thomas Maurer’s Study Guide - Likewise, the fantastic Thomas Maurer has just released, like as of 3/30, his offering. Free! | . Practice Tests . Official MeasureUp Practice Test. - You can also find this on the Microsoft AZ-900 Exam Page. I wanted something I could iterate with as a measuring stick regarding the exam objectives. That way, I could see where I would need to focus my studying. There’s also a test pass gurantee for what it’s worth. | Chris Pietschmann and Dan Patrick’s Self Assessment tool - This really isn’t a practice test so much as it is a tool for keeping track of your progress, but because it makes you continually reassess yourself, this seems like the natural place for it. Free! | . Podcasts . CloudSkills.io Podcast Episode 39 - This podcast features excellent host Mike Pfeiffer talking with Tim Warner about how to prepare for this very exam. | CloudSkills.io Podcast Episode 48 - Another podcast where Mike and Tim discuss this exam. This time even discussing Tim Warner’s Microsoft Ignite presentation on prep for it. | . So, there’s a lot of momentum around this exam, and it seems like some new hotness for prepping for it is being released almost daily. I’m curious as to what others are using to prepare. Do you use a resource not listed here? Leave a comment below and let me know what it is please! I’ll get it added. Also, I’d be curious to know your approach and if I’m just being paranoid about the difficulty as it relates to the breadth of the content that could be covered. I’d love to hear your feedback! Thanks and good luck in your studies! .",
            "url": "https://azurebrian.github.io/blog/training/2020/03/31/AZ900-Prep.html",
            "relUrl": "/training/2020/03/31/AZ900-Prep.html",
            "date": " • Mar 31, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Launch!!!",
            "content": "Greetings! I wanted to write a few lines to capture the milestone represented by this post – it’s the first one! I’m excited about what this means in terms of my journey in this space, but I do hope it will be a resource for others who are looking for good, helpful Azure-related content as well. Just a quick shout out to some of the folks that have inspired me to launch this blog: . Tim Warner | Chris Pietschmann | Thomas Maurer | John Savill | Troy Hunt | . I respect each of the above’s expertise first and foremost, and have garnered so much knowledge from their blog posts, Pluralsight courses, newsletters, podcasts, and Twitter accounts. I also admire greatly their professionalism in the way they brand and market themselves. That’s the “blueprint”, pardon the pun :smirk:, I’m shooting for here. I hope that as I learn I can give back to the community, as they have. . So, please stay tuned for upcoming posts on topics such as: . AZ-900 Azure Fundamentals Certification | Azure Network Troubleshooting Tools | Hybrid connections with VNAs (Virtual Network Appliances) | . If you want to be informed of these posts as they’re published, be sure to follow me on Twitter and link to the Atom feed (buttons for both are in the sidebar to the right). Also, if there are any topics you’d like to see covered, feel free to leave a comment below (Github account required). . Thanks and I look forward to sharing more soon! . Brian .",
            "url": "https://azurebrian.github.io/blog/general/2020/03/26/launch.md%20Go%20to%20file",
            "relUrl": "/general/2020/03/26/launch.md%20Go%20to%20file",
            "date": " • Mar 26, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://azurebrian.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://azurebrian.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://azurebrian.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://azurebrian.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}